<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>GraphFill: Deep Image Inpainting using Graphs</title>
    <link rel="icon" type="image/x-icon" href="static/images/faviconme.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                DMD-Net: Deep Mesh Denoising Network
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="#">Aalok Gangopadhyay</a
                  ><sup>*</sup>,</span
                >
                <span class="author-block">
                  <a href="#">Shashikant Verma</a><sup>*</sup>,</span
                >
                <span class="author-block">
                  <a href="#">Shanmuganathan Raman</a><sup
                  ></sup>,</span
                >
                
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  > CVIG Lab<br />
                  <sup></sup>Indian Institute of Technology Gandhinagar, India
                  <br />ICPR 
                  2022</span
                >
                <span class="eql-cntrb"
                  ><small
                    ><br /><sup>*</sup>Indicates Equal Contribution</small
                  ></span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a
                      href="static/pdfs/main.pdf"
                    
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <span class="link-block">
                    <a
                      href="static/pdfs/supplementary_material.pdf"
                    
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="#"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <!-- <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/<ARXIV PAPER ID>"
                    
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span> -->
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser video-->
    <!-- <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/banner_video.mp4" type="video/mp4" />
          </video>
          <h2 class="subtitle has-text-centered">
            Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus
            tellus, maximus vel lectus at, placerat pretium mi. Maecenas
            dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut
            maximus.
          </h2>
        </div>
      </div>
    </section> -->
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning framework, for solving the mesh denoising problem. DMD-Net consists of a Graph Convolutional Neural Network in which aggregation is performed in both the primal as well as the dual graph. This is realized in the form of an asymmetric two-stream network, which contains a primal-dual fusion block that enables communication between the primal-stream and the dual-stream. We develop a Feature Guided Transformer (FGT) paradigm, which consists of a feature extractor, a transformer, and a denoiser. The feature extractor estimates the local features, that guide the transformer to compute a transformation, which is applied to the noisy input mesh to obtain a useful intermediate representation. This is further processed by the denoiser to obtain the denoised mesh. Our network is trained on a large scale dataset of 3D objects. We perform exhaustive ablation studies to demonstrate that each component in our network is essential for obtaining the best performance. We show that our method obtains competitive or better results when compared with the state-of-the-art mesh denoising algorithms. We demonstrate that our method is robust to various kinds of noise. We observe that even in the presence of extremely high noise, our method achieves excellent performance.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="item">
                <img src="static/images/res.PNG" alt="Architecture" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <!-- Image carousel -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/d3d.PNG" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
              </h2>
            </div>
            <div class="item">
              <!-- Your image here -->
              <img src="static/images/res.PNG" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                
              </h2>
            </div>
            <div class="item">
              <img src="static/images/arch.PNG" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
              </h2>
            </div>
            <!-- <div class="item">
              <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Fourth image description.
              </h2>
            </div> -->
          </div>
        </div>
      </div>
    </section>
    <!-- End image carousel -->

    <!-- Youtube video -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <!-- Paper video. -->
          <h2 class="title is-3">Video Presentation</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="publication-video">
                <!-- Youtube embed code here -->
                <iframe width="560" height="315" src="https://www.youtube.com/embed/wPJvUYqiL94?si=QcZ01G5t_XqP0Dkk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End youtube video -->



    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{gangopadhyay2022dmd,
          title={DMD-Net: deep mesh denoising network},
          author={Gangopadhyay, Aalok and Verma, Shashikant and Raman, Shanmuganathan},
          booktitle={2022 26th International Conference on Pattern Recognition (ICPR)},
          pages={3168--3175},
          year={2022},
          organization={IEEE}
        }</code></pre>
      </div>
    </section>
  </body>
</html>
